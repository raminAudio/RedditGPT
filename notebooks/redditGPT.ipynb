{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835c75aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import sys\n",
    "import numpy as np\n",
    "from matplotlib.pylab import plt\n",
    "pd.options.mode.chained_assignment = None\n",
    "from IPython.display import Image, display\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import ast\n",
    "from dataclasses import dataclass\n",
    "from contextlib import nullcontext\n",
    "import pickle, dill\n",
    "from unidecode import unidecode\n",
    "\n",
    "sys.path.insert(1, '../')\n",
    "from utils.data_utility import DataUtil\n",
    "from utils.helper import estimate_loss, get_batch\n",
    "from utils.attention_block import GPTLanguageModel\n",
    "from tokenizers import ByteLevelBPETokenizer\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be7836ea",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173e54bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skip this step and go to the next cell if you have your own text file you want to use.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9505c0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_data = '../data/'\n",
    "dutil = DataUtil()\n",
    "df_science = pd.read_csv(path_to_data + 'askscience_data.csv').drop('Unnamed: 0',axis=1)\n",
    "texts  = list(df_science['title'].dropna())\n",
    "texts += list(df_science['body'].dropna())\n",
    "\n",
    "text_data = [\" \".join(y.lower().replace('?',' ?').replace(\"!\",\" \").replace(',',' ').replace(';',' ').replace(\"\\\"\",\"\").replace('(',' ').replace(')',' ').replace('[',' ').replace(': ',' ').replace(']',' ').replace(\". \",\" . \").replace('-',' ').replace('*','').replace(\"“\",\"\").replace(\"”\",\"\").replace('_',' ').split()) for y in texts] # vectorized text data\n",
    "text_data = [unidecode(y) for y in text_data ] # vectorized text data\n",
    "final_text = []\n",
    "for y in text_data:\n",
    "    ws = []\n",
    "    for w in y.split():\n",
    "        if 'http' not in w: # vectorized text data\n",
    "            ws.append(w)\n",
    "    final_text.append(\"<s> \" +  ' '.join(ws).replace('/',' ')+ \" </s>\")\n",
    "        \n",
    "text_data = final_text         \n",
    "\n",
    "FromDrive = 0\n",
    "myOwn = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79761e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(path_to_data + 'training_text.txt','w')\n",
    "for t in text_data: \n",
    "    f.write( \"<s> \" + t + \" </s>\")\n",
    "    f.write(' \\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a3856bd",
   "metadata": {},
   "source": [
    "# Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c2f259",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "path = [path_to_data + 'training_text.txt']\n",
    "# Initialize a tokenizer\n",
    "tokenizer = ByteLevelBPETokenizer()\n",
    "\n",
    "# Customize training\n",
    "tokenizer.train(files=path, vocab_size=52_000, min_frequency=2, special_tokens=[\n",
    "    \"<s>\",\n",
    "    \"<pad>\",\n",
    "    \"</s>\",\n",
    "    \"<unk>\",\n",
    "    \"<mask>\",\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075f400e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.enable_padding(pad_token='</s>')\n",
    "end_token_id = tokenizer.token_to_id('</s>')\n",
    "start_token_id = tokenizer.token_to_id('<s>')\n",
    "pad_token_id = end_token_id\n",
    "\n",
    "\n",
    "encode = lambda s: tokenizer.encode(s).ids\n",
    "decode = lambda l: tokenizer.decode(l)\n",
    "\n",
    "vocab_size = tokenizer.get_vocab_size()\n",
    "print(\"number of words \" , vocab_size)\n",
    "\n",
    "tokenizer.encode('<s> hi how are you? </s>').ids\n",
    "# Save files to disk\n",
    "tokenizer.save_model(path_to_data, \"redditTok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e35111",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = ByteLevelBPETokenizer(path_to_data + 'redditTok-vocab.json', path_to_data +'redditTok-merges.txt')\n",
    "pad_token_id = tokenizer.token_to_id('</s>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707befac",
   "metadata": {},
   "outputs": [],
   "source": [
    "len_tokens = [len(encode(x)) for x in text_data]\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.hist(len_tokens,20);\n",
    "\n",
    "ax = plt.gca()\n",
    "\n",
    "plt.title(\"Distribution of # of tokens\")\n",
    "plt.xlabel(\"Number of tokens in a sequence\")\n",
    "plt.ylabel(\"Count\")\n",
    "ax.set_xlim([0, 300])\n",
    "\n",
    "print(f\"median lenght %d \"%np.median(len_tokens))\n",
    "\n",
    "block_size = 64 \n",
    "tokenizer.enable_truncation(max_length=block_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6249ae6f",
   "metadata": {},
   "source": [
    "# Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b930321",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_iters = 221\n",
    "eval_interval = 40\n",
    "learning_rate = 1e-5\n",
    "eval_iters = 20\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class GPTConfig:\n",
    "    block_size: int = block_size\n",
    "    vocab_size: int = vocab_size\n",
    "    n_layer: int = 6\n",
    "    n_head: int = 4\n",
    "    n_embd: int = 512\n",
    "    dropout: float = 0.2\n",
    "    batch_size: int = 32\n",
    "    temperature=1.0 \n",
    "    top_k=20\n",
    "        \n",
    "config = GPTConfig()\n",
    "\n",
    "dill.dump(config,open(path_to_data + 'scratch_reddit_gpt_config.pickle','wb'))\n",
    "\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "\n",
    "ptdtype = {'float32': torch.float32, 'bfloat16': torch.bfloat16, 'float16': torch.float16}['float16']\n",
    "ctx = nullcontext() if device == 'cpu' else torch.amp.autocast(device_type=device, dtype=ptdtype)\n",
    "\n",
    "\n",
    "torch.manual_seed(1337)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37929329",
   "metadata": {},
   "source": [
    "Chunking data to be around median length. could help avoiding adding too many padding tokens later "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6228007a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = []\n",
    "for text in text_data :\n",
    "    words_ = text.split()\n",
    "    b = [0,config.block_size]\n",
    "    if len(words_) >= config.block_size: \n",
    "            words_seg = words_[b[0]:b[1]]\n",
    "            sequences.append(' '.join(words_seg))\n",
    "            b[0] += config.block_size\n",
    "            b[1] += config.block_size\n",
    "    else: \n",
    "        sequences.append(' '.join(words_))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3dcd77b",
   "metadata": {},
   "source": [
    "# Train and validation splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117761c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# padding sequences to be of the same size\n",
    "data_ids = []\n",
    "for seq in sequences:\n",
    "    ids = encode(seq)\n",
    "    if len(ids) == block_size: \n",
    "        ids[0] = start_token_id\n",
    "        ids[-1] = end_token_id\n",
    "        \n",
    "    elif len(ids) < block_size: \n",
    "        ids[0] = start_token_id\n",
    "        ids[-1] = pad_token_id\n",
    "        while len(ids) != block_size: \n",
    "            ids.append(pad_token_id)\n",
    "        ids[-1] = end_token_id\n",
    "    data_ids.append(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250c3e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ids = torch.tensor(data_ids, dtype=torch.long)\n",
    "\n",
    "n = int(0.95*len(data_ids)) # first 95% will be train, rest val\n",
    "train_data = data_ids[:n]\n",
    "val_data = data_ids[n:]\n",
    "\n",
    "print(\"Number of training data \" , len(train_data))\n",
    "print(\"Number of validation data \" , len(val_data))\n",
    "\n",
    "pickle.dump(train_data , open(path_to_data + 'train_data.pickle','wb'))\n",
    "pickle.dump(val_data , open(path_to_data + 'valid_data.pickle','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce2e1cee",
   "metadata": {},
   "source": [
    "## Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a7b11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"trianing data (batch_size %d , block_size %d)\"%(get_batch('train')[0].shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae6b3f7",
   "metadata": {},
   "source": [
    "# Self Attention - Decoder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d6e4ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Image(filename='../snapshots/head.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5f394f8",
   "metadata": {},
   "source": [
    "To paraphrase Andrej K., \n",
    "\n",
    "\" We want the [words] to know about each other, information from the past.  Every single token emits two vectors, a query anda a key vector. Query is what am I looking for and key is what do I contain? The dot product of these two vector is maximized when the query and key are aligned which helps attention learn more about that specific token. \"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd850bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "B = 1 # batch size\n",
    "T = 16 # time stamps\n",
    "C = 32 # embedding dim\n",
    "head_size = 16 # head size \n",
    "x = torch.randn(B,T,C) # token embedding\n",
    "\n",
    "key   = nn.Linear(C, head_size, bias=False) # (C, hs)\n",
    "query = nn.Linear(C, head_size, bias=False) # (C, hs)\n",
    "\n",
    "k = key(x)  # (B, T, hs)\n",
    "q = query(x)# (B, T, hs)\n",
    "\n",
    "# Dot product followed by scaling \n",
    "# Scaling is important for softmax, specially in the early layers. \n",
    "# Scaling will help reduce the std ensuring the values won't get too large \n",
    "# in the softmax \n",
    "\n",
    "wei = q @ k.transpose(-2,-1) * k.shape[-1]**-0.5 \n",
    "tril = torch.tril(torch.ones(T, T))\n",
    "wei = wei.masked_fill(tril==0,float('-inf'))\n",
    "wei = F.softmax(wei,dim=-1) # (B, T, T)\n",
    "v = wei @ x\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.imshow(wei.detach().numpy()[0,:,:])\n",
    "plt.title(\"Self Attention Weights\")\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.imshow(v.detach().numpy()[0,:,:])\n",
    "plt.title(\"v before Lora\")\n",
    "\n",
    "# add LoRA \n",
    "rank = 8\n",
    "W_A = nn.Parameter(torch.empty(T, rank)) # LoRA weight A\n",
    "W_B = nn.Parameter(torch.empty(rank, C))\n",
    "nn.init.kaiming_uniform_(W_A, a=np.sqrt(5))\n",
    "nn.init.zeros_(W_B)\n",
    "\n",
    "v += W_A@W_B\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.imshow(v.detach().numpy()[0,:,:])\n",
    "plt.title(\"v after Lora\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847a3164",
   "metadata": {},
   "source": [
    "# hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9817f6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From scratch\n",
    "if FromDrive == 0:\n",
    "    model = GPTLanguageModel(config)\n",
    "    m = model.to(device)\n",
    "else:\n",
    "    print(\"loading from cache\")\n",
    "    # Further training an existing one\n",
    "    model  = torch.load(path_to_data + 'scratch_reddit_gpt2')\n",
    "    m = model.to(device)\n",
    "    config = pickle.load(open(path_to_data + 'scratch_reddit_gpt_config.pickle','rb'))\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "print(sum([p.numel()/1e6 for p in m.parameters() if p.requires_grad]) , 'M trainable parameters')\n",
    "print( \"random loss\" , -np.log10(1/vocab_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f07cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = '<s>'\n",
    "context = torch.tensor([encode(start)], dtype=torch.long, device=device)\n",
    "        \n",
    "for iter_ in range(max_iters):\n",
    "    if iter_> 1 and iter_ % eval_interval == 0 or iter_ == max_iters - 1:\n",
    "        decoded_context = decode(m.generate(context, max_new_tokens=32)[0].tolist())\n",
    "        print(' '.join(decoded_context.split()))\n",
    "        losses = estimate_loss()\n",
    "        print(\"---\")\n",
    "        print(f\"step {iter_}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f} \\n\")\n",
    "        print(\"####################################################\")\n",
    "        \n",
    "    # sample a batch of data\n",
    "    xb, yb = get_batch('train')\n",
    "\n",
    "    # evaluate the loss\n",
    "    with ctx:\n",
    "        logits, loss = model(xb, yb)\n",
    "        \n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d02d60",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Saving model and artifacts\n",
    "torch.save(m, '../data/scratch_reddit_gpt_2' )\n",
    "dill.dump(config,open(path_to_data + 'scratch_reddit_gpt_config.pickle','wb'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a55256",
   "metadata": {},
   "source": [
    "# Decoding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba608807",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate from the model\n",
    "start = 'how'\n",
    "context = torch.tensor([encode(start)], dtype=torch.long, device=device)\n",
    "decoded_context = decode(m.generate(context, max_new_tokens=config.block_size)[0].tolist())\n",
    "print(' '.join(decoded_context.split()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67fd0f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d523f620",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
